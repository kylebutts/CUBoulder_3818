---
title: "ECON 3818"
subtitle: "Expectations"
author: "Kyle Butts"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  xaringan::moon_reader:
    css: ['default']
    self_contained: true
nature:
  highlightStyle: github
highlightLines: true
countIncrementalSlides: false
---
exclude: true

```{R, setup, include = F}

library(tidyverse)
library(svglite)
library(knitr)
library(here)
library(gt)
library(patchwork)
library(kfbmisc)

# Knitr options
opts_chunk$set(
    comment = "#>",
    fig.align = "center",
    fig.height = 7,
    fig.width = 10.5,
    warning = F,
    message = F
)

# Use svg for figures
opts_chunk$set(dev = "svg")
options(device = function(file, width, height) {
    svg(tempfile(), width = width, height = height)
})

# HTML output for knitr
options(knitr.table.format = "html")


make_gt_title <- function(title) {
    gt::html(glue::glue("<span class='hi slate' style='display: block; margin-bottom: 8px;'>{title}</span>"))
}

xaringanExtra::use_scribble()
```

---
class: clear, middle
<!-- Custom css -->
```{css, echo = F, code=xfun::read_utf8(here::here("Lecture Slides", "my-css.css"))}
```


<!-- From xaringancolor -->

<div style = "position:fixed; visibility: hidden">
$$
\require{color}
\definecolor{purple}{rgb}{0.337254901960784, 0.00392156862745098, 0.643137254901961}
\definecolor{navy}{rgb}{0.0509803921568627, 0.23921568627451, 0.337254901960784}
\definecolor{ruby}{rgb}{0.603921568627451, 0.145098039215686, 0.0823529411764706}
\definecolor{alice}{rgb}{0.0627450980392157, 0.470588235294118, 0.584313725490196}
\definecolor{daisy}{rgb}{0.92156862745098, 0.788235294117647, 0.266666666666667}
\definecolor{coral}{rgb}{0.949019607843137, 0.427450980392157, 0.129411764705882}
\definecolor{kelly}{rgb}{0.509803921568627, 0.576470588235294, 0.337254901960784}
\definecolor{jet}{rgb}{0.0745098039215686, 0.0823529411764706, 0.0862745098039216}
\definecolor{asher}{rgb}{0.333333333333333, 0.372549019607843, 0.380392156862745}
\definecolor{slate}{rgb}{0.192156862745098, 0.309803921568627, 0.309803921568627}
\definecolor{cranberry}{rgb}{0.901960784313726, 0.254901960784314, 0.450980392156863}
$$
</div>
	
<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
		TeX: {
			Macros: {
				purple: ["{\\color{purple}{#1}}", 1],
				navy: ["{\\color{navy}{#1}}", 1],
				ruby: ["{\\color{ruby}{#1}}", 1],
				alice: ["{\\color{alice}{#1}}", 1],
				daisy: ["{\\color{daisy}{#1}}", 1],
				coral: ["{\\color{coral}{#1}}", 1],
				kelly: ["{\\color{kelly}{#1}}", 1],
				jet: ["{\\color{jet}{#1}}", 1],
				asher: ["{\\color{asher}{#1}}", 1],
				slate: ["{\\color{slate}{#1}}", 1],
				cranberry: ["{\\color{cranberry}{#1}}", 1]
			},
			loader: {load: ['[tex]/color']},
			tex: {packages: {'[+]': ['color']}}
		}
	});
</script>

<style>
	.purple {color: #5601A4;}
	.navy {color: #0D3D56;}
	.ruby {color: #9A2515;}
	.alice {color: #107895;}
	.daisy {color: #EBC944;}
	.coral {color: #F26D21;}
	.kelly {color: #829356;}
	.jet {color: #131516;}
	.asher {color: #555F61;}
	.slate {color: #314F4F;}
	.cranberry {color: #E64173;}
</style>


```{r flair_color, echo=FALSE}
	library(flair)
	purple <- "#5601A4"
	navy <- "#0D3D56"
	ruby <- "#9A2515"
	alice <- "#107895"
	daisy <- "#EBC944"
	coral <- "#F26D21"
	kelly <- "#829356"
	jet <- "#131516"
	asher <- "#555F61"
	slate <- "#314F4F"
	cranberry <- "#E64173"
```

## Expectations

---
# Outline

.hi.coral[Expectation]

- Definition
- Properties


.hi.ruby[Variance]

- Definiton
- Properties
      




---
# What are Expectations?

We are familiar with expectations. For example, 

- What salary can I expect to earn after graduating from college?
- I will not invest in Facebook because I expect its sock price to fall in the future
- If you complete your homework, you should expect to do well on exams 

In statistics, the idea of expectation has a formal, mathematical definition. 

Most of econometrics revolves around finding the best .it[conditional expectation] (we'll discuss this concept later in the course)


---
# Expectation: Discrete Case

First we give the mathematical definition of .hi.coral[expectation] for discrete random variables.

Let $X$ be a discrete random variable with pmf $p_X(x)$. 

The .hi.purple[expectation] of $X$, denoted $E(X)$ or $\mu$, is: 
$$ 
E(X)= \sum_{x \in S} x\cdot p_X(x), 
$$

where $S$ is the sample space and x is a realization of the random variable $X$

The expectation is essentially the .hi[weighted average] of the possible outcomes of $X$, or the .it[mean].
 

---
# Example of Discrete Expectation

Suppose we roll a six-sided .it[unfair] die. The probability of each outcome is provided below:

```{r unfair-die, echo=F}
dice <- tibble(x = c(1, 2, 3, 4, 5, 6), `P_X(x)` = c(1 / 10, 1 / 10, 1 / 10, 1 / 10, 1 / 2, 1 / 10))

gt(dice) %>%
    gt_theme_kyle()
```

What is the expected outcome of a single throw? By definition:

\begin{aligned}
  E(X) &= \sum_{x=1}^6 x\cdot p_x(x) \\
  &= (1\cdot 0.1) + (2\cdot 0.1) + (3\cdot 0.1) + (4\cdot 0.1) + (5\cdot 0.5) + (6\cdot 0.1) \\
  &= 4.1
\end{aligned}


---
# Clicker Question -- Midterm Example
Assume $X$ can only obtain the values $1, 2, 3,$ and $5$. Given the following PMF, what is $E(X)$?

```{r missing-pmf, echo=F}
missing <- tibble(x = c(1, 2, 3, 5), `P_X(x)` = c("0.1", "0.2", "0.2", "?"))

gt(missing) %>%
    gt_theme_kyle() %>%
    tab_header(title = make_gt_title("Unfair Die"))
```

<ol type = "a">
  <li>1.1</li>
  <li>3.6</li>
  <li>3.1</li>
  <li>Cannot be determined from information</li>
</ol>





---
# Expectation: Continuous Case

How would you define an expectation of a continuous random variable?

Let $Y$ be the continuous random variable with pdf $f_Y(u)$. Then the expectation of $Y$ is

$$
  E(Y)= \int^\infty_{-\infty}y \cdot f_Y(y) dy
$$

This is still a weighted average! $y$ is the value you observe and $f_Y(y)$ is the density which is just the relative likelihood or .it[weight].

.it[Don't forget to multiply by y!]


---
# Example of Continuous Expectation

Suppose $Y$ is a continuous random variable with the pdf $f_Y(y)=3y^2$ for $0<y<1$. Then:

\begin{equation}
  E(Y) = \int_{-\infty}^{\infty}y\cdot f_Y(y) \ dy = \int_{0}^{1}y \cdot 3y^2 \ dy = \int_{0}^{1} 3y^3 \ dy = \left.\frac{3}{4}y^4 \ \right|_0^1  = \frac{3}{4}
\end{equation}


---
# Clicker Question

Suppose $X$ has a .hi.cranberry[uniform distribution] over $(a,b)$ denoted 

$X \sim U(a,b)$. That is, $f_x(x) = \frac{1}{b-a}$ for $a<x<b$. What is $E(X)$?

.more-left[
```{r unif-dist, echo = F, out.width = "90%"}
ggplot(data.frame(x = -2.5:2.5), aes(.data$x)) +
    stat_function(
        fun = function(x) {
            dunif(x, -1, 1)
        },
        xlim = c(-2.5, -1.00000000001),
        color = "black", size = 1.5
    ) +
    stat_function(
        fun = function(x) {
            dunif(x, -1, 1)
        },
        xlim = c(-0.9999999, 0.9999999),
        color = "black", size = 1.5
    ) +
    stat_function(
        fun = function(x) {
            dunif(x, -1, 1)
        },
        xlim = c(1.00000000001, 2.5),
        color = "black", size = 1.5
    ) +
    geom_segment(
        data = tibble(x = c(-1, 1), y = c(0, 0), xend = c(-1, 1), yend = c(0.5, 0.5)),
        mapping = aes(x = x, y = y, xend = xend, yend = yend),
        linetype = "dashed"
    ) +
    scale_x_continuous(breaks = c(-1, 1), labels = c("a", "b")) +
    scale_y_continuous(breaks = c(0, 0.5), labels = c(0, "1/(b-a)"), limits = c(0, 0.8)) +
    theme_kyle(base_size = 20) +
    labs(x = "Value", y = "Density")
```
]

.less-right[
<ol type = "a">
  <li>\(\frac{b-a}{2}\)</li>
  <li>\(\frac{b+a}{2}\)</li>
  <li>\(\frac{1}{b-a}\)</li>
  <li>\(1\)</li>
</ol>
]




---
# Midterm Example

Consider the probability distribution for random variable X:

$$
  f(x)=.08x,\  0\leq x \leq 5
$$

Find $E[X]$



---
# Properties of Expectation
A trick that will make our lives easier is that expectations are a .hi.purple[linear operator] which means you can move constants in and out of the $E$ function. 

Let $X, Y$ be random variables and $a, b$ be constants. Then:

- $E(a) = a$

- $E(aX) = aE(X)$

- $E(X + b) = E(X) + b$

- $E(aX+b) = aE(X) + b$

- $E(X + Y) = E(X) + E(Y)$



---
# Clicker Question
Suppose that the expected income in Boulder is $90,000 and the tax rate is 10%. Then the post-tax income is Y=0.9X where $X$ is annual income of a Boulder resident. What is the expected post-tax income for a Boulder resident, E(Y)?

<ol type = "a">
  <li>$8,000</li>
  <li>$90,000</li>
  <li>$9,000</li>
  <li>$81,000</li>
</ol>



---
# Definition of Variance

Recall the variance of a sample is $$s^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \bar{X})^2$$

We can use expectations to define a similar expression for the population variance. 

Let $X$ be a random variable with $E(X)< \infty$. Then the .hi.ruby[variance] of $X$ is:

$$ 
  Var(X) = E[(X-E(X))^2] 
$$

Imagine writing this out as an integral and solving it. Would not be fun. .it[Instead, we will be using a much simpler equation to calculate variance...]


---
# Alternate Form
Note that we can write,

\begin{aligned}
Var(X) &= E[ \left(X - E(X) \right)^2 ] = E[ X^2 - 2X\cdot E(X) + [E(X)]^2 ] \\
       &= E(X^2) - 2E(X)\cdot E(X) + [E(X)]^2                                \\
       &= E(X^2) - 2[E(X)]^2 + [E(X)]^2                                      \\
       &= E(X^2) - [E(X)]^2,                                                 
\end{aligned}

$$Var(X)=E(X^2)-[E(X)]^2$$ is a much simpler expression of variance (and the one you should use!)


---
# Properties of Expectation
We can compose E with a function of a random variable, g(X).

$$ 
  E[g(X)]= \sum_{x\in S} g(x) \cdot p_x(x)
$$ 

The result is the expected value of g(X). We will use this property to calculate $E[X^2]$


---
# Example

While $E(X)$ is called the .hi.kelly[first moment], we call $E(X^2)$ the .hi.coral[second moment] of X. 

Therefore, we calculate $E[X^2]$ using the following equation: 

$$ E[X^2] = \sum x^2*p_X(x) $$

or in the continuous case

$$
  \int_{-\infty}^\infty x^2 f_X(x) dx
$$



---
# Example

Let $X$ be the number of heads in two coin flips. 

$$ 
E(X) = 0 \cdot (\frac{1}{4})+ 1 \cdot (\frac{1}{2}) + 2 \cdot (\frac{1}{4}) = \frac{1}{2} + \frac{1}{2} = 1
$$

--
$$ 
E(X^2) = 0^2 \cdot (\frac{1}{4})+ 1^2 \cdot (\frac{1}{2}) + 2^2 \cdot  (\frac{1}{4}) = \frac{1}{2} + 1 = \frac{3}{2} ^{\color{cranberry}*}
$$

This means that 
$$V(X)=E(X^2)-[E(X)]^2 = \frac{3}{2}-1^2 = \frac{1}{2}$$

.footnote[.cranberry[<sup>*</sup>].hi[Never] square probabilities when solving \(E(X^2)\). Only square \(X\) values]


---
# Properties of Variance
There are several important properties of the variance operator:

- $Var(a) = 0$

- $Var(aX) = a^2Var(X)$

- $Var(aX+b) = a^2Var(X)$

- $Var(aX+bY) = a^2Var(X)+b^2Var(Y)+2ab\cdot Cov(X,Y).$<sup>.cranberry[*]</sup> 

.footnote[.cranberry[<sup>*</sup>] We will discuss more about covariance later, when $X$ and $Y$ are independent then the covariance is zero]



---
# Clicker Question
Recall that in Boulder the mean income is $90,000 and the tax rate is 10%. Suppose that the variance of income in Boulder is $1,000. What is the variance of post-tax income, $Y=0.9X$?

<ol type = "a">
  <li>$900</li>
  <li>$1000</li>
  <li>$810</li>
  <li>$800</li>
</ol>



---
# Midterm Example

Consider the probability distribution for random variable Y

$$
  f(x)=.08x, 0\leq x \leq 5
$$

Find $V[X]$:

\begin{aligned}
  V[X] &= \int_{-\infty}^\infty x^2 * f(x) \ dx - \left[ \int_{-\infty}^\infty x * f(x) \ dx \right]^2 \\
  &= \int_0^5 x^2 * .08x \ dx - \left[\int_0^5 x * .08x \ dx \right]^2= \int_0^5 .08x^3 \ dx - \left[  \int_0^5 .08x^2 \ dx \right]^2 \\
  &= \frac{.08x^4}{4} \ \Big|_0^5 - \left( \frac{.08x^3}{3} \ \Big|_0^5\right) ^2= 12.5-(3.3)^2=1.61 
\end{aligned}




---
# Midterm Example

Consider the probability distribution for random variable X:

```{r pmf-example-2, echo = F}
pmf <- tibble(x = c(2,4,6,8), `P_X(x)` = c("0.19", "0.07", "0.35", "p"))

gt(pmf) %>%
  gt_theme_kyle()
```

1. Find the expectation of X
2. Find the variance of X
3. A friend says, the expected value of $X$ is 5. To justify this he says, "Well $X$ could be 2,4,6, or 8, so the average is $\frac{2+4+6+8}{4} = 5$". Why is your friend wrong? Why isn't $E[X]=5?$ (1-2) sentences. 
4. Let $Y\sim N(4,1)$. Random variable $W$ is defined as $W=2X+3Y$. Given your information about the random variables $X$ and Y. What is $E[W]$? What is $Var[W]$? (assuming $X$ & $Y$ are independent) }



---
# Midterm Example
Consider the probability distribution for random variable Y:

$$
  f(y)= 8y, 0\leq y \leq \frac{1}{2}
$$

1. Find $E[Y]$
2. Find $P(Y<\frac{1}{3})$
3. Find $P(Y=\frac{1}{4})$
4. Find $V[Y]$
5. Find $P(\frac{3}{4}<Y<1)$


