---
title: "ECON 3818"
subtitle: "Chapter 16"
author: "Kyle Butts"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  xaringan::moon_reader:
    css: ['default']
    self_contained: true
nature:
  highlightStyle: github
highlightLines: true
countIncrementalSlides: false
---
exclude: true

```{R, setup, include = F}

library(tidyverse)
library(svglite)
library(knitr)
library(here)
library(gt)
library(patchwork)
library(kfbmisc)

# Knitr options
opts_chunk$set(
comment = "#>",
fig.align = "center",
fig.height = 7,
fig.width = 10.5,
warning = F,
message = F
)

# Use svg for figures
opts_chunk$set(dev = "svglite")
options(device = function(file, width, height) {
svglite::svglite(tempfile(), width = width, height = height)
})

# HTML output for knitr
options(knitr.table.format = "html")


make_gt_title <- function(title) {
gt::html(glue::glue("<span class='hi slate' style='display: block; margin-bottom: 8px;'>{title}</span>"))
}

xaringanExtra::use_scribble()
```

---
class: clear, middle
<!-- Custom css -->
```{css, echo = F, code=xfun::read_utf8(here::here("Lecture Slides", "my-css.css"))}
```


<!-- From xaringancolor -->

<div style = "position:fixed; visibility: hidden">
$$\require{color}\definecolor{purple}{rgb}{0.337254901960784, 0.00392156862745098, 0.643137254901961}$$
$$\require{color}\definecolor{navy}{rgb}{0.0509803921568627, 0.23921568627451, 0.337254901960784}$$
$$\require{color}\definecolor{ruby}{rgb}{0.603921568627451, 0.145098039215686, 0.0823529411764706}$$
$$\require{color}\definecolor{alice}{rgb}{0.0627450980392157, 0.470588235294118, 0.584313725490196}$$
$$\require{color}\definecolor{daisy}{rgb}{0.92156862745098, 0.788235294117647, 0.266666666666667}$$
$$\require{color}\definecolor{coral}{rgb}{0.949019607843137, 0.427450980392157, 0.129411764705882}$$
$$\require{color}\definecolor{kelly}{rgb}{0.509803921568627, 0.576470588235294, 0.337254901960784}$$
$$\require{color}\definecolor{jet}{rgb}{0.0745098039215686, 0.0823529411764706, 0.0862745098039216}$$
$$\require{color}\definecolor{asher}{rgb}{0.333333333333333, 0.372549019607843, 0.380392156862745}$$
$$\require{color}\definecolor{slate}{rgb}{0.192156862745098, 0.309803921568627, 0.309803921568627}$$
$$\require{color}\definecolor{cranberry}{rgb}{0.901960784313726, 0.254901960784314, 0.450980392156863}$$
</div>
	
<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
		TeX: {
			Macros: {
				purple: ["{\\color{purple}{#1}}", 1],
				navy: ["{\\color{navy}{#1}}", 1],
				ruby: ["{\\color{ruby}{#1}}", 1],
				alice: ["{\\color{alice}{#1}}", 1],
				daisy: ["{\\color{daisy}{#1}}", 1],
				coral: ["{\\color{coral}{#1}}", 1],
				kelly: ["{\\color{kelly}{#1}}", 1],
				jet: ["{\\color{jet}{#1}}", 1],
				asher: ["{\\color{asher}{#1}}", 1],
				slate: ["{\\color{slate}{#1}}", 1],
				cranberry: ["{\\color{cranberry}{#1}}", 1]
			},
			loader: {load: ['[tex]/color']},
			tex: {packages: {'[+]': ['color']}}
		}
	});
</script>

<style>
	.purple {color: #5601A4;}
	.navy {color: #0D3D56;}
	.ruby {color: #9A2515;}
	.alice {color: #107895;}
	.daisy {color: #EBC944;}
	.coral {color: #F26D21;}
	.kelly {color: #829356;}
	.jet {color: #131516;}
	.asher {color: #555F61;}
	.slate {color: #314F4F;}
	.cranberry {color: #E64173;}
</style>


```{r flair_color, echo=FALSE}
	library(flair)
	purple <- "#5601A4"
	navy <- "#0D3D56"
	ruby <- "#9A2515"
	alice <- "#107895"
	daisy <- "#EBC944"
	coral <- "#F26D21"
	kelly <- "#829356"
	jet <- "#131516"
	asher <- "#555F61"
	slate <- "#314F4F"
	cranberry <- "#E64173"
```

## Chapter 16: Confidence Intervals

---
# Statistical Inference

Recall, we're interested in estimating some unknown .cranberry[population] parameter $\theta$ using the .kelly[sample] $X_1, ...,X_n$

We can use some estimator $\hat{\theta}$
      
- We can find its bias and its variance

- Can say what it converges to using Law of Large Numbers and the Central Limit Theorem
      
However, we don't have $n \to \infty$. We have a .hi[finite] sample. 

- Therefore, we want to construct some belief about how good our estimator is.

- For example, if we have a sample mean with 5 individuals, our sampling distribution has a large variance. We want to report that.


---
# Example

Say we collect ACT Scores for 654 students, and calculate $\bar{X}_{654}=26.8$. Somehow we also know that the standard deviation of the *population distribution* is $\sigma$ = 7.5

To visualize:

```{r 68-95-99, echo = F, out.width = "75%"}

# From svmiller
plot_sd_rule <- function(mean, sd) {

ggplot(data.frame(x = c(mean - 4*sd, mean + 4*sd)), aes(.data$x)) +
    # +/- 1
    stat_function(
        fun = function(x) dnorm(x, mean, sd),
        xlim = c(mean - 1*sd, mean + 1*sd), size = 0,
        geom = "area", fill = "#d2382c", alpha = 0.5
    ) +
    # +/- 2
    stat_function(
        fun = function(x) dnorm(x, mean, sd),
        xlim = c(mean - 2*sd, mean + 2*sd), size = 0,
        geom = "area", fill = "#d2382c", alpha = 0.4
    ) +
    # +/- 3
    stat_function(
        fun = function(x) dnorm(x, mean, sd),
        xlim = c(mean - 3*sd, mean + 3*sd), size = 0,
        geom = "area", fill = "#d2382c", alpha = 0.3
    ) +
    # +/- 1 sd
    geom_segment(
        x = mean + 1*sd, y = 0, xend = mean + 1*sd, yend = dnorm(mean + 1*sd, mean, sd),
        color = "white", linetype = "dashed"
    ) +
    geom_segment(
        x = mean - 1*sd, y = 0, xend = mean - 1*sd, yend = dnorm(mean + 1*sd, mean, sd),
        color = "white", linetype = "dashed"
    ) +
    # +/- 2 sd
    geom_segment(
        x = mean + 2*sd, y = 0, xend = mean + 2*sd, yend = dnorm(mean + 2*sd, mean, sd),
        color = "white", linetype = "dashed"
    ) +
    geom_segment(
        x = mean - 2*sd, y = 0, xend = mean - 2*sd, yend = dnorm(mean + 2*sd, mean, sd),
        color = "white", linetype = "dashed"
    ) +
    # 68%
    annotate(
        geom = "text", x = mean, y = dnorm(mean + 1*sd, mean, sd),
        label = "68%", size = 4.5, color = "white"
    ) +
    geom_segment(
        x = mean - 1*.1*sd, y = dnorm(mean + 1*sd, mean, sd), xend = mean - 1*0.95*sd, yend = dnorm(mean + 1*sd, mean, sd),
        color = "white",
        arrow = arrow(length = unit(0.15, "cm"))
    ) +
    geom_segment(
        x = mean + 1*.1*sd, y = dnorm(mean + 1*sd, mean, sd), xend = mean + 1*0.95*sd, yend = dnorm(mean + 1*sd, mean, sd),
        color = "white",
        arrow = arrow(length = unit(0.15, "cm"))
    ) +
    # 95%
    annotate(
        geom = "text", x = mean, y = dnorm(mean + 2*sd, mean, sd),
        label = "95%", size = 4.5, color = "white"
    ) +
    geom_segment(
        x = mean - 2*.1*sd, y = dnorm(mean + 2*sd, mean, sd), xend = mean - 2*0.95*sd, yend = dnorm(mean + 2*sd, mean, sd),
        color = "white",
        arrow = arrow(length = unit(0.15, "cm"))
    ) +
    geom_segment(
        x = mean + 2*.1*sd, y = dnorm(mean + 2*sd, mean, sd), xend = mean + 2*0.95*sd, yend = dnorm(mean + 2*sd, mean, sd),
        color = "white",
        arrow = arrow(length = unit(0.15, "cm"))
    ) +
	# 99%
    annotate(
        geom = "text", x = mean, y = dnorm(mean + 3*sd, mean, sd),
        label = "99%", size = 4.5, color = "white"
    ) +
    geom_segment(
        x = mean - 3*.1*sd, y = dnorm(mean + 3*sd, mean, sd), xend = mean - 3*0.95*sd, yend = dnorm(mean + 3*sd, mean, sd),
        color = "white",
        arrow = arrow(length = unit(0.15, "cm"))
    ) +
    geom_segment(
        x = mean + 3*.1*sd, y = dnorm(mean + 3*sd, mean, sd), xend = mean + 3*0.95*sd, yend = dnorm(mean + 3*sd, mean, sd),
        color = "white",
        arrow = arrow(length = unit(0.15, "cm"))
    ) +
    # Normal curve
    stat_function(fun = function(x) dnorm(x, mean, sd), color = "black", size = 1.5) +
    theme_kyle(base_size = 20) +
    labs(x = "Value", y = "Density")
}

plot_sd_rule(26.8, 7.5)

```


---
# Confidence Interval

The 95 part of the 68-95-99.7 rule for Normal distributions says that $\bar{X}_{654}$ is within 2 standard deviations of the mean $\mu$ in 95% of samples. 


Since $\sigma=7.5$, the standard deviation of our sampling distribution is $\frac{7.5}{\sqrt{654}}=0.3$ (from the Central Limit Theorem). 

This means for .hi[95% of all samples of size 654], the sample mean $\bar{X}_{654}$ is within $0.6$ of the populatin mean (two std deviations).

<br>

If we estimate that $\mu$ lies somewhere in the interval from $\bar{X}_{654}-0.6$ to $\bar{X}_{654}+0.6$, we'll be right for 95% of all possible samples.


---
# Confidence Interval

Plugging in all the information we have leads to:

$$\big[26.8-0.6, 26.8+0.6\big] = \big[ 26.2, 27.4 \big]$$

This interval is a .hi.ruby[confidence interval], which says that we are .it[95% confident] that the true mean of the BMI, $\mu$, is in between 26.2 and 27.4 .sup[*]


.footnote[.sup[*] This is because we got this interval from a method that captures the population mean for 95% of all possible samples]




---
# Confidence Intervals

Let's see what I mean. Let's say the population average ACT Score is 27. I will draw many samples of size 654 from the distribution $N(27, 7.5)$. 

For each sample, I will calculate $\bar{X}_{654}$ and add and subtract $0.6$ to form my confidence interval $[\bar{X}_{654}-0.6, \bar{X}_{654}+0.6]$.


```{r ci-coverage, echo = F, out.width = "75%"}

# This makes sure we get the same random numbers every time
set.seed(123)

# Setting the parameters of the simulation
sample_size <- 100
num_samples <- 50
ci_level <- 0.95

# theoretical pop mean / standard deviation (sd) for standard normal
pop_mean <- 27
pop_sd <- 7.5

# What we will store sample means into 
sample_means <- c()

for(i in 1:num_samples){
	# Draw normal random variable
	sample <- rnorm(n= sample_size, mean= pop_mean, sd= pop_sd)
	
	# Mean 
	sample_mean <- mean(sample)
	
	# Store result in position `i` from loop.
	sample_means[i] <- sample_mean
}

# finding the margin of error
moe <- qnorm(1 - (1-ci_level)/2) * pop_sd / sqrt(sample_size)

# binding x\bar-moe and x\bar+moe as two columns
CI <- data.frame(CI_lower= sample_means - moe, CI_upper= sample_means + moe)

# to make the nice picture, you need the user written package ggplot2
## you might need to type: install.packages("ggplot2") into the console if you get an error
require(ggplot2)

# a logical vector, TRUE if the confidence interval captures the population mean
CI$is_mu_in_CI <- ((pop_mean > CI$CI_lower) & (pop_mean < CI$CI_upper))

## making the plot
ci_coverage <- ggplot() +
	geom_linerange(
	aes(x = 1:num_samples,
	    ymin = CI$CI_lower, 
	    ymax = CI$CI_upper, 
	    col = CI$is_mu_in_CI,
	    )
	) + 
	scale_color_manual(values = c("TRUE" = kelly, "FALSE" = cranberry)) +
	guides(col = "none") +
	labs(title = "Confidence Intervals", x = "Sample Number") +
	geom_hline(yintercept = pop_mean, col = "black", linetype = "dashed") +
	scale_y_continuous(limits = c(pop_mean - 0.75 * pop_sd, pop_mean + 0.75 * pop_sd)) +
	kfbmisc::theme_kyle(base_size = 20)

ci_coverage

```





---
# Confidence Intervals

In that example, the confidence interval was $\bar{X}_{654} \pm 0.6$. In general, a confidence interval takes the form 

$${\color{kelly} \text{estimate}} \pm {\color{daisy} \text{margin of error}}$$

where the .hi.daisy[margin of error] shows how much variability there is in our estimate


---
# Margins of Error

For a given level of confidence, $C$ (say 95%), the .daisy[margin of error] for our sample mean as: 

$$
{\color{daisy} k} = Z_{\frac{1-C}{2}}} \frac{\sigma}{\sqrt{n}}
$$

<br>

- Let's say $C = 95\%$. We want to capture the middle 95%, so $\frac{1-.95}{2} = 2.5\%$ in each tail. 

- $Z_{0.025} = 1.96$ which is where the $\sim 2$ standard deviations comes from.



- 90% Confidence Interval:  $\implies Z_{\frac{1-C}{2}} = Z_{.05} = 1.645$ standard deviations.


---
# Example
Lets determine the .it[exact] margin of error for previous example

$$k=Z_{\frac{1-C}{2}} \cdot \frac{\sigma}{\sqrt{n}}$$


If we are calculating 95% confidence interval, where $\bar{X}_{654}=26.8$ $\sigma = 7.5$,  then

$$k=Z_{0.025} \cdot \frac{7.5}{\sqrt{654}}$$

We find $Z_{0.025}$ using the table. $Z_{0.025}$ is the z-score such that $P(z>Z_{0.025})=0.025$

- Look up 0.025 (or 0.975!) and find the corresponding z-score 

---
# Example

Using the z-table, we find that $Z_{0.025} = 1.96$. This means:

$$k = 1.96\cdot \frac{7.5}{\sqrt{654}} = 0.57$$

This means our .it[exact] 95% confidence interval is:

$$[26.23, 27.37]$$


---
# Clicker Question

What Z-score will be associated with a 82% confidence interval

<ol type = "a">
	<li>0.92</li>
	<li>1.34</li>
	<li>0.82</li>
	<li>0.79</li>
</ol>



---
# Example

Say high-school freshmen are sampled to see how long they spend on social media per day. The sample mean of $n = 50$ students is $\bar{X}_{50} = 2.1$ hours. The standard deviation of the population is $0.5$ hours. 

What is the 90% confidence interval for our estimate of the mean number of hours per day?


---
# Clicker Question
A 95% confidence interval for the mean hours freshmen spent on social media per day was calculated to be [2.5 hours, 3.1 hours] based off a sample mean $\bar{X}_{50} = 2.8$. The confidence interval was based on a SRS sample of $n = 50$. 

The standard deviation of the population is:

<ol type = "a">
	<li>0.3</li>
	<li>1.96</li>
	<li>0.2772</li>
	<li>1.0823</li>
</ol>


---
# Margins of Error

So to recap, the margin of error is calculated by:

$$k=Z_{\frac{1-C}{2}} \cdot \frac{\sigma}{\sqrt{n}}$$

This means the size of the margin of error is determined by:

- level of confidence

- size of sample (can sometimes control)

- variance (which we can't control)

Discuss with a partner what happens to margin of error when

- increase the level of confidence required

- decrease sample size

- increase variance of population


---
# Margins of Error

Level of confidence
      
- higher the level of confidence we want to have, larger the margin of error
      
Size of sample 
      
- larger the sample, smaller the margin of error
      
- Variance
      
larger the variance, larger the margin of error
      



---
# Example

Given a sample mean of 8, from a sample of 36 observations, and a variance of 25, construct 90%, 95%, and 99% confidence intervals for the true value, $\mu$. 


---
# Confidence Intervals

How to .hi[properly] think of a confidence interval:

1. You collect many different samples from the population

2. For each sample, you calculate the mean and the associated confidence interval around that mean

3. You'll have a confidence interval for each sample you collected

4. .hi[95% of the confidence intervals you calculated will include the true mean $\mu$]



---
# Confidence Intervals

*Common misconceptions* about confidence intervals


The CI .hi.ruby[does not] tell you:
      
- The true mean is inside the confidence interval

- The probability the true mean is in your CI is C%
      
      
The CI .hi.kelly[does] tell you:
      
- the range of estimates that contain the true mean C% of the time *in repeated sampling*
      
      
      
---
# Confidence Intervals

```{r, echo = F, out.width = "90%"}
ci_coverage
```





---
# Clicker Question -- Midterm Example
Veterinary researchers at a major university veterinary hospital calculated a 99% confidence interval for the average age of horses admitted for laminitis (a particular foot disease) as 6.3 to 7.4 years. 

Based on this information we conclude that:

<ol type = "a">
	<li> 99% of all horses admitted for laminitis are between 6.3 and 7.4 years old </li>
	
	<li> 99% of the time, the average age of a horse admitted for laminitis will be between 6.3 and 7.4 years </li>
	
	<li> We are 99% confident that the true mean age of horses with laminitis is between 6.3 and 7.4 years old </li>
	
	<li> 99% of all samples of size n=25 will have an average age of horses with laminitis between 6.3 and 7.4 years old. </li>
</ol>



